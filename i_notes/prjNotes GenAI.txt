NEW KEYWORDS{

    transformers in genAI : consist of an encoder and decoder;

    upstream tast vs downstream task in ai foundation models{

        upstream{

            task on which the model is dependent;
            when the model need a training data;
            its includes input data;
        }

        downstreak{

            task which is affected by the model;
            when prompt is given and data is received by the model;
        }
    }

    npl: natural language processing;

    Responsible AI;

    knowledge cuttoff: llm having knowledge of stuff only till the time it was trained;

    hallucination;
}

to-do{
    

}

terms to remember{

    supervised-unsupervised learning;
    regression-classification problems;

    https://www.geeksforgeeks.org/difference-between-artificial-intelligence-vs-machine-learning-vs-deep-learning/

    ai->ml->dl->genAI;
}

genAI{

    these are large language models;

    it comes under deep learning, which uses neural networks;

    these models are used to produce data such as text, images, audios, etc;
    where as models that is used to produce a label, discrete values, numbers, etc. does not comes under genAI;
}

deep learning{

    it uses neural networks;
    it uses semi-supervised learning i.e. both supervised(most part) and unsupervised data is used for learning;

    deep learning models can be categorized into 2 types{

        discriminative{

            where you train a model to predict output of new inputs, regression and classification problems;
        }

        generative{

            where you train a model to create new data points;
        }
    }

}

neural networks{

    its inspired from our brain;
}

llm{

    large language models;
    its build using self-supervised learning with deep learning;

    these are models that are pre-trained and can be fine-tuned for specific purposes;

    3 major features{

        large{

            large training data set;
            large no. of parameters;
        }

        general purpose{

            can solve common problems;
            such as text recognization, document sumarization, text generation, etc.; 

            resource is restricted as the large amount of data required for training are available to limited organizations only;
        }

        pretrained and fine tune{

            pretrain a llm for a general purpose with large dataset;
            then fine tune the model for specific purpose with much smaller dataset; 

        }

    }

    benefits: 
        a single llm can be used for different tasks (general purpose tasks);
        can be trailored/fine-tuned for a specific task with minimal data;
        performance is growing with increasing no. of data and parameters;
    
    demerits{

        expensive to train;
        result can be biased;
        can be used for generating harmful content;
    }

    concerns{

        hallucination: making things up, when the model generated content that are unreallistic, fictional or completely fabricated;

        factuality: truthfullness of the information;

        anthropomorphization: attribution of human-like qualities to non-human entities, such as AI;
    }

    eg.{

        palm{

            Pathway language model;
            it is a tranformer model;
    
        }
        
        lamda{

            language model for dialogue application;
        }
    }

    for llm development, you only need prompt design;
}

self-supervised learning{

    allows machine learning algorithms to use observed inputs to predict unknown inputs;
    by observed input it means that the input and output label is not mentioned and the model have to itself learn it and form input and output label and make it a supervised learning;
    
    goal for self-supervised learning is to programmatically change unsupervised learning models into supervised learning models;
    done by developing pre-training deep learning systems that can learn to fill in missing information;
}

prompt design vs engineering{

    design{

        creating a prompt that is tailored for a specific task; 
    }

    engineering{

        process of creating a prompt that is designed to improve performance;
        involve using domain-specific knowledge, providing examples of the desired output;
    }  
}

google ai principles for responsible ai{

    7 to do's{

        1. be socially beneficial;
        2. avoid creating or reinforcing unfair biases;
        3. be built and tested for safety;
        4. be accountable to people;
        5. incorporate privacy design principles;
        6. uphold high standards for scientific excellence;
        7. be made available for uses that accord to these principles
    }

    4 to don't{

        1. likely to cause overall harm;
        2. weapons or other technologies whose principle purpose is to cause injury to people;
        3. surveillence violating internationally accepted norms;
        4. those who contravenes international law and human rights;
    }
}


coursera Andrew NG{

    differnt platforms for GenAI{

        chatGPT from openAI;
        bard/gemini from Goggle;
        bing/copilot from Microsoft;
    }

    AI already in our live{

        web search;
        fraud detection in payment and critical network connections;
        recommendation system;
    }

    input/output length is limited in llm;

    genAI currently does not work with structured data (tabular data), supervised learning is a better technique for it;

    image generation{

        using diffusion model with self-supervised learning;

        diffusion model: breaking the data and rebuilding it, making the image noisy and then removing the noise;
    }

    using genAI in software{

        using general ai model vs genAI model{

            general model{

                we generally use supervised learning;
                we collect data;
                label the data;
                train the model;
                deploy the model;
            }

            genAI{

                we use llm api;
                we make suitable prompt;
                test the result and fine tune the prompt;
                deploy the application;
            }
        }

        methods to improve genAI result{

            prompt designing;
            RAG (Retrieval augmented generation), giving model excess to external data source, it modifies the prompt and add another level of input data in it;
            fine tune model, in this the llm model is trained on a smaller amount of supervised data;
            pretrain model: train LLM from scratch, very costly and can be done by big companies;
        }

        token{

            words used in input and output are used to calculate no. of tokens;
            it is then used for applying usage cost of llm;
            typically 1 token = 3/4 of 1 word;
        }

        instruction training{

            its like fine tuning the llm;
            it this instead of predecting the next word to complete the sentence, it predicts the next word to answer the question asked;
        }

        RLHF{

            reinforcement learing from human feedback;
            helps in providing helpful,honest and harmless (aka triple H) output;

            in this the output is given rewards/feedback and thus the model trains to get higher scores;
        }

        tools{

            tools are like functions with pre-defined instructions;
            as the llm can be irregular in operations involving a particular mathematical task or task which have a particular order of operations then in this case a tool can be used;

            eg. calculator, placing an order, doing transaction;
        }

        agents{

            its a new cutting edge technology using genAI that is still evolving;
            agents are like a bots or programme that can perform a set instruction on the internet just like humans with addition to their own unique capabilities;

            its tha basis of LAM that in being used in rabbit r1;
        }

        analysing a job for augmentation/automation using genAI{

            a job consists of many smaller tasks;
            one can analyse these tasks to determine if AI can be used in these particular tasks;
            one can check the feaseability of AI for the task and also the business value for implementing it;

            oNET has done some review/research on certain jobs for this;
        }

        AGI{

            artificial general ai;
            ai that can do any kind of intellectual tasks that human can do, basically a human persona;
        }

    }
}